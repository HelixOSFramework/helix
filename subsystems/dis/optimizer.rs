//! # Adaptive Optimizer - ML-Inspired Runtime Optimization
//!
//! The Adaptive Optimizer uses runtime statistics and pattern detection to
//! automatically tune scheduling parameters, predict task behavior, and
//! optimize resource allocation.
//!
//! ## Optimization Techniques
//!
//! 1. **Time Slice Optimization**
//!    - Adjust time slices based on task behavior
//!    - CPU-bound tasks get longer slices
//!    - Interactive tasks get shorter, more frequent slices
//!
//! 2. **Priority Adjustment**
//!    - Boost interactive tasks
//!    - Decay long-running CPU hogs
//!    - Balance fairness with responsiveness
//!
//! 3. **CPU Affinity Optimization**
//!    - Group related tasks on same cache domain
//!    - Spread independent tasks for parallelism
//!    - Minimize cache thrashing
//!
//! 4. **Load Prediction**
//!    - Predict future CPU usage
//!    - Anticipate burst patterns
//!    - Pre-allocate resources
//!
//! ## Architecture
//!
//! ```text
//! ┌──────────────────────────────────────────────────────────────────────────┐
//! │                          ADAPTIVE OPTIMIZER                               │
//! │                                                                           │
//! │  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────────────┐   │
//! │  │  PATTERN        │  │  PREDICTION     │  │  OPTIMIZATION           │   │
//! │  │  ANALYZER       │  │  ENGINE         │  │  ENGINE                 │   │
//! │  │                 │  │                 │  │                         │   │
//! │  │  • Detect       │  │  • Forecast     │  │  • Time slice tuning    │   │
//! │  │    workload     │  │    CPU load     │  │  • Priority adjustment  │   │
//! │  │  • Identify     │  │  • Predict      │  │  • Affinity hints       │   │
//! │  │    phases       │  │    bursts       │  │  • Queue balancing      │   │
//! │  │  • Classify     │  │  • Estimate     │  │  • Energy optimization  │   │
//! │  │    tasks        │  │    resources    │  │  • Memory placement     │   │
//! │  └─────────────────┘  └─────────────────┘  └─────────────────────────┘   │
//! │                                                                           │
//! │  ┌─────────────────────────────────────────────────────────────────────┐  │
//! │  │                    LEARNING ENGINE                                   │  │
//! │  │                                                                      │  │
//! │  │   • Track optimization outcomes                                      │  │
//! │  │   • Reinforce successful strategies                                  │  │
//! │  │   • Avoid ineffective optimizations                                  │  │
//! │  │   • Adapt to workload changes                                        │  │
//! │  └─────────────────────────────────────────────────────────────────────┘  │
//! └──────────────────────────────────────────────────────────────────────────┘
//! ```

use alloc::boxed::Box;
use alloc::collections::{BTreeMap, VecDeque};
use alloc::string::{String, ToString};
use alloc::vec::Vec;
use core::sync::atomic::{AtomicU64, AtomicU32, AtomicBool, Ordering};
use spin::RwLock;

use super::{TaskId, CpuId, Nanoseconds, DISError, DISResult};
use super::stats::{TaskStats, BehaviorPattern, SystemStats, StatsCollector};
use super::intent::IntentClass;

// =============================================================================
// Optimization Hints
// =============================================================================

/// Hints generated by the optimizer for the scheduler
#[derive(Debug, Clone)]
pub struct OptimizationHint {
    /// Target task
    pub task_id: TaskId,
    /// Hint type
    pub hint_type: HintType,
    /// Priority (higher = more important)
    pub priority: u8,
    /// Confidence level (0-100)
    pub confidence: u8,
    /// Reason for hint
    pub reason: HintReason,
    /// Timestamp
    pub timestamp: Nanoseconds,
}

/// Types of optimization hints
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum HintType {
    /// Adjust time slice
    TimeSlice(TimeSliceHint),
    /// Adjust priority
    Priority(PriorityHint),
    /// CPU affinity suggestion
    Affinity(AffinityHint),
    /// Queue placement
    Queue(QueueHint),
    /// Energy optimization
    Energy(EnergyHint),
    /// Memory placement
    Memory(MemoryHint),
    /// Frequency scaling
    Frequency(FrequencyHint),
}

/// Time slice adjustment hint
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct TimeSliceHint {
    /// Recommended time slice in nanoseconds
    pub recommended: Nanoseconds,
    /// Current time slice
    pub current: Nanoseconds,
    /// Adjustment direction
    pub direction: AdjustmentDirection,
    /// Percentage change
    pub change_percent: i8,
}

/// Priority adjustment hint
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct PriorityHint {
    /// Recommended priority
    pub recommended: i8,
    /// Current priority
    pub current: i8,
    /// Temporary boost?
    pub temporary: bool,
    /// Duration of boost (if temporary)
    pub duration: Option<Nanoseconds>,
}

/// CPU affinity hint
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct AffinityHint {
    /// Recommended CPUs
    pub recommended_cpus: Vec<CpuId>,
    /// Preferred CPU (if any)
    pub preferred: Option<CpuId>,
    /// Avoid these CPUs
    pub avoid_cpus: Vec<CpuId>,
    /// Reason
    pub affinity_reason: AffinityReason,
}

/// Queue placement hint
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct QueueHint {
    /// Recommended queue
    pub recommended: QueueLevel,
    /// Current queue
    pub current: QueueLevel,
}

/// Energy optimization hint
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct EnergyHint {
    /// Recommended power state
    pub power_state: PowerState,
    /// Allow frequency scaling
    pub allow_scaling: bool,
    /// Minimum frequency (MHz)
    pub min_freq: u32,
    /// Maximum frequency (MHz)
    pub max_freq: u32,
}

/// Memory placement hint
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct MemoryHint {
    /// Preferred NUMA node
    pub preferred_node: u32,
    /// Memory locality importance (0-100)
    pub locality_importance: u8,
    /// Huge pages recommended
    pub huge_pages: bool,
}

/// Frequency scaling hint
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct FrequencyHint {
    /// Target frequency (MHz)
    pub target_freq: u32,
    /// Allow turbo boost
    pub allow_turbo: bool,
}

/// Adjustment direction
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AdjustmentDirection {
    Increase,
    Decrease,
    NoChange,
}

/// Reason for affinity hint
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AffinityReason {
    CacheLocality,
    NUMALocality,
    LoadBalancing,
    Isolation,
    Grouping,
    Exclusive,
}

/// Queue levels
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum QueueLevel {
    RealTime,
    Interactive,
    Normal,
    Batch,
    Background,
    Idle,
}

/// Power states
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PowerState {
    Performance,
    Balanced,
    PowerSave,
    Idle,
}

/// Reason for optimization hint
#[derive(Debug, Clone)]
pub enum HintReason {
    PatternDetected(BehaviorPattern),
    PerformanceIssue(String),
    ResourceContention(String),
    EnergyOptimization,
    LoadBalancing,
    LatencyImprovement,
    ThroughputImprovement,
    FairnessCorrection,
    DeadlineMiss,
    Custom(String),
}

// =============================================================================
// Prediction Engine
// =============================================================================

/// Prediction engine for future behavior
pub struct PredictionEngine {
    /// Historical CPU load data
    cpu_history: RwLock<VecDeque<LoadSample>>,
    /// Per-task prediction models
    task_models: RwLock<BTreeMap<TaskId, TaskPredictionModel>>,
    /// Prediction accuracy tracking
    accuracy: PredictionAccuracy,
    /// Configuration
    config: PredictionConfig,
}

/// CPU load sample
#[derive(Debug, Clone)]
pub struct LoadSample {
    pub timestamp: Nanoseconds,
    pub load: u8,
    pub runnable: u32,
}

/// Task behavior prediction model
#[derive(Debug, Clone, Default)]
pub struct TaskPredictionModel {
    /// Execution time predictions
    exec_time_avg: Nanoseconds,
    exec_time_variance: u64,
    /// Wait time predictions
    wait_time_avg: Nanoseconds,
    /// Burst probability (0-100)
    burst_probability: u8,
    /// Sleep probability (0-100)
    sleep_probability: u8,
    /// Samples collected
    samples: u32,
    /// Model confidence (0-100)
    confidence: u8,
}

/// Prediction accuracy tracking
#[derive(Debug, Default)]
struct PredictionAccuracy {
    predictions_made: AtomicU64,
    predictions_correct: AtomicU64,
}

/// Prediction configuration
#[derive(Debug, Clone)]
pub struct PredictionConfig {
    /// History length for averaging
    pub history_length: usize,
    /// Minimum samples for prediction
    pub min_samples: u32,
    /// Confidence threshold
    pub confidence_threshold: u8,
}

impl Default for PredictionConfig {
    fn default() -> Self {
        Self {
            history_length: 100,
            min_samples: 5,
            confidence_threshold: 70,
        }
    }
}

impl PredictionEngine {
    /// Create new prediction engine
    pub fn new(config: PredictionConfig) -> Self {
        Self {
            cpu_history: RwLock::new(VecDeque::with_capacity(config.history_length)),
            task_models: RwLock::new(BTreeMap::new()),
            accuracy: PredictionAccuracy::default(),
            config,
        }
    }
    
    /// Record CPU load sample
    pub fn record_load(&self, timestamp: Nanoseconds, load: u8, runnable: u32) {
        let sample = LoadSample { timestamp, load, runnable };
        
        let mut history = self.cpu_history.write();
        if history.len() >= self.config.history_length {
            history.pop_front();
        }
        history.push_back(sample);
    }
    
    /// Update task model
    pub fn update_task_model(&self, task_id: TaskId, stats: &TaskStats) {
        let mut models = self.task_models.write();
        let model = models.entry(task_id).or_insert(TaskPredictionModel::default());
        
        // Update execution time average using exponential moving average
        let alpha = 0.3f64;
        let new_exec = stats.avg_exec_time.raw() as f64;
        let old_exec = model.exec_time_avg.raw() as f64;
        let avg_exec = alpha * new_exec + (1.0 - alpha) * old_exec;
        model.exec_time_avg = Nanoseconds::new(avg_exec as u64);
        
        // Update variance
        let diff = (new_exec - avg_exec).abs();
        let old_var = model.exec_time_variance as f64;
        let new_var = alpha * diff * diff + (1.0 - alpha) * old_var;
        model.exec_time_variance = new_var as u64;
        
        // Update probabilities
        model.burst_probability = stats.burst_score;
        model.sleep_probability = 100 - stats.cpu_percent;
        
        model.samples += 1;
        
        // Update confidence
        model.confidence = (model.samples.min(100) as u8)
            .saturating_sub(((model.exec_time_variance / 1_000_000) as u8).min(50));
    }
    
    /// Predict CPU load for next interval
    pub fn predict_cpu_load(&self, lookahead: Nanoseconds) -> LoadPrediction {
        let history = self.cpu_history.read();
        
        if history.len() < 3 {
            return LoadPrediction {
                predicted_load: 50,
                confidence: 10,
                trend: LoadTrend::Stable,
            };
        }
        
        // Calculate trend
        let recent: Vec<u8> = history.iter().rev().take(10).map(|s| s.load).collect();
        let older: Vec<u8> = history.iter().rev().skip(10).take(10).map(|s| s.load).collect();
        
        let recent_avg: u32 = recent.iter().map(|&x| x as u32).sum::<u32>() / recent.len().max(1) as u32;
        let older_avg: u32 = older.iter().map(|&x| x as u32).sum::<u32>() / older.len().max(1) as u32;
        
        let trend = if recent_avg > older_avg + 5 {
            LoadTrend::Increasing
        } else if recent_avg + 5 < older_avg {
            LoadTrend::Decreasing
        } else {
            LoadTrend::Stable
        };
        
        // Predict based on trend
        let predicted = match trend {
            LoadTrend::Increasing => (recent_avg + 10).min(100) as u8,
            LoadTrend::Decreasing => recent_avg.saturating_sub(10) as u8,
            LoadTrend::Stable => recent_avg as u8,
        };
        
        let confidence = (history.len().min(50) * 2) as u8;
        
        LoadPrediction {
            predicted_load: predicted,
            confidence,
            trend,
        }
    }
    
    /// Predict task behavior
    pub fn predict_task_behavior(&self, task_id: TaskId) -> TaskPrediction {
        let models = self.task_models.read();
        
        if let Some(model) = models.get(&task_id) {
            if model.confidence >= self.config.confidence_threshold {
                return TaskPrediction {
                    next_exec_time: model.exec_time_avg,
                    likely_burst: model.burst_probability > 50,
                    likely_sleep: model.sleep_probability > 50,
                    confidence: model.confidence,
                };
            }
        }
        
        TaskPrediction {
            next_exec_time: Nanoseconds::from_millis(10),
            likely_burst: false,
            likely_sleep: false,
            confidence: 0,
        }
    }
    
    /// Get prediction accuracy
    pub fn accuracy(&self) -> f64 {
        let made = self.accuracy.predictions_made.load(Ordering::Relaxed);
        let correct = self.accuracy.predictions_correct.load(Ordering::Relaxed);
        
        if made == 0 {
            return 0.0;
        }
        
        (correct as f64 / made as f64) * 100.0
    }
}

/// Load prediction result
#[derive(Debug, Clone)]
pub struct LoadPrediction {
    pub predicted_load: u8,
    pub confidence: u8,
    pub trend: LoadTrend,
}

/// Load trend
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum LoadTrend {
    Increasing,
    Decreasing,
    Stable,
}

/// Task behavior prediction
#[derive(Debug, Clone)]
pub struct TaskPrediction {
    pub next_exec_time: Nanoseconds,
    pub likely_burst: bool,
    pub likely_sleep: bool,
    pub confidence: u8,
}

// =============================================================================
// Optimization Strategies
// =============================================================================

/// Strategy for optimizing a specific aspect
pub trait OptimizationStrategy: Send + Sync {
    /// Name of the strategy
    fn name(&self) -> &str;
    
    /// Evaluate and generate hints for a task
    fn evaluate_task(&self, task_id: TaskId, stats: &TaskStats, system: &SystemStats) -> Option<OptimizationHint>;
    
    /// Evaluate system-wide and generate hints
    fn evaluate_system(&self, system: &SystemStats) -> Vec<OptimizationHint>;
    
    /// Update strategy based on outcome
    fn update(&mut self, hint: &OptimizationHint, success: bool);
}

/// Time slice optimization strategy
pub struct TimeSliceStrategy {
    /// Minimum time slice
    min_slice: Nanoseconds,
    /// Maximum time slice
    max_slice: Nanoseconds,
    /// Default time slice
    default_slice: Nanoseconds,
    /// Success rate tracking
    success_rate: f64,
    /// Total adjustments made
    adjustments: u64,
}

impl TimeSliceStrategy {
    pub fn new() -> Self {
        Self {
            min_slice: Nanoseconds::from_millis(1),
            max_slice: Nanoseconds::from_millis(100),
            default_slice: Nanoseconds::from_millis(10),
            success_rate: 0.5,
            adjustments: 0,
        }
    }
}

impl OptimizationStrategy for TimeSliceStrategy {
    fn name(&self) -> &str {
        "time_slice"
    }
    
    fn evaluate_task(&self, task_id: TaskId, stats: &TaskStats, _system: &SystemStats) -> Option<OptimizationHint> {
        // Determine optimal time slice based on behavior
        let recommended = match stats.behavior_pattern {
            BehaviorPattern::CpuBound => {
                // CPU-bound: longer slices to reduce overhead
                Nanoseconds::from_millis(50)
            }
            BehaviorPattern::Interactive => {
                // Interactive: short slices for responsiveness
                Nanoseconds::from_millis(4)
            }
            BehaviorPattern::IoBound => {
                // I/O-bound: moderate slices
                Nanoseconds::from_millis(10)
            }
            BehaviorPattern::Bursty => {
                // Bursty: adaptive based on burst score
                let base = 5 + stats.burst_score as u64 / 5;
                Nanoseconds::from_millis(base)
            }
            BehaviorPattern::Background => {
                // Background: longer slices, less scheduling
                Nanoseconds::from_millis(100)
            }
            _ => return None,
        };
        
        // Only generate hint if significantly different from current
        let avg_exec = stats.avg_exec_time;
        if avg_exec > Nanoseconds::zero() {
            let diff_percent = if recommended > avg_exec {
                ((recommended.raw() - avg_exec.raw()) * 100 / avg_exec.raw()) as i8
            } else {
                -(((avg_exec.raw() - recommended.raw()) * 100 / avg_exec.raw()) as i8)
            };
            
            if diff_percent.abs() < 20 {
                return None;
            }
        }
        
        Some(OptimizationHint {
            task_id,
            hint_type: HintType::TimeSlice(TimeSliceHint {
                recommended,
                current: self.default_slice,
                direction: if recommended > self.default_slice {
                    AdjustmentDirection::Increase
                } else {
                    AdjustmentDirection::Decrease
                },
                change_percent: 0,
            }),
            priority: 50,
            confidence: stats.interactive_score,
            reason: HintReason::PatternDetected(stats.behavior_pattern),
            timestamp: Nanoseconds::zero(),
        })
    }
    
    fn evaluate_system(&self, _system: &SystemStats) -> Vec<OptimizationHint> {
        Vec::new()
    }
    
    fn update(&mut self, _hint: &OptimizationHint, success: bool) {
        self.adjustments += 1;
        let alpha = 0.1;
        self.success_rate = alpha * (if success { 1.0 } else { 0.0 }) + (1.0 - alpha) * self.success_rate;
    }
}

/// Priority adjustment strategy
pub struct PriorityStrategy {
    /// Interactive boost amount
    interactive_boost: i8,
    /// CPU hog penalty
    hog_penalty: i8,
    /// Maximum boost duration
    max_boost_duration: Nanoseconds,
    /// Success tracking
    success_rate: f64,
}

impl PriorityStrategy {
    pub fn new() -> Self {
        Self {
            interactive_boost: 5,
            hog_penalty: -3,
            max_boost_duration: Nanoseconds::from_millis(100),
            success_rate: 0.5,
        }
    }
}

impl OptimizationStrategy for PriorityStrategy {
    fn name(&self) -> &str {
        "priority"
    }
    
    fn evaluate_task(&self, task_id: TaskId, stats: &TaskStats, _system: &SystemStats) -> Option<OptimizationHint> {
        // Interactive boost
        if stats.interactive_score > 70 && stats.cpu_percent < 30 {
            return Some(OptimizationHint {
                task_id,
                hint_type: HintType::Priority(PriorityHint {
                    recommended: self.interactive_boost,
                    current: 0,
                    temporary: true,
                    duration: Some(self.max_boost_duration),
                }),
                priority: 60,
                confidence: stats.interactive_score,
                reason: HintReason::LatencyImprovement,
                timestamp: Nanoseconds::zero(),
            });
        }
        
        // CPU hog penalty
        if stats.cpu_percent > 90 && stats.preemptions > stats.voluntary_switches * 3 {
            return Some(OptimizationHint {
                task_id,
                hint_type: HintType::Priority(PriorityHint {
                    recommended: self.hog_penalty,
                    current: 0,
                    temporary: true,
                    duration: Some(self.max_boost_duration),
                }),
                priority: 40,
                confidence: 80,
                reason: HintReason::FairnessCorrection,
                timestamp: Nanoseconds::zero(),
            });
        }
        
        None
    }
    
    fn evaluate_system(&self, _system: &SystemStats) -> Vec<OptimizationHint> {
        Vec::new()
    }
    
    fn update(&mut self, _hint: &OptimizationHint, success: bool) {
        let alpha = 0.1;
        self.success_rate = alpha * (if success { 1.0 } else { 0.0 }) + (1.0 - alpha) * self.success_rate;
    }
}

/// Load balancing strategy
pub struct LoadBalanceStrategy {
    /// Imbalance threshold (0-100)
    imbalance_threshold: u8,
    /// Migration cooldown
    migration_cooldown: Nanoseconds,
}

impl LoadBalanceStrategy {
    pub fn new() -> Self {
        Self {
            imbalance_threshold: 20,
            migration_cooldown: Nanoseconds::from_millis(10),
        }
    }
}

impl OptimizationStrategy for LoadBalanceStrategy {
    fn name(&self) -> &str {
        "load_balance"
    }
    
    fn evaluate_task(&self, task_id: TaskId, stats: &TaskStats, system: &SystemStats) -> Option<OptimizationHint> {
        // Skip if too many migrations already
        if stats.migrations > 10 {
            return None;
        }
        
        // Find underloaded CPUs
        let avg_load: u32 = system.per_cpu_load.iter()
            .map(|c| c.load as u32)
            .sum::<u32>() / system.per_cpu_load.len().max(1) as u32;
        
        let underloaded: Vec<CpuId> = system.per_cpu_load.iter()
            .filter(|c| (c.load as u32) < avg_load.saturating_sub(self.imbalance_threshold as u32))
            .map(|c| c.cpu_id)
            .collect();
        
        let overloaded: Vec<CpuId> = system.per_cpu_load.iter()
            .filter(|c| (c.load as u32) > avg_load + self.imbalance_threshold as u32)
            .map(|c| c.cpu_id)
            .collect();
        
        if !underloaded.is_empty() && !overloaded.is_empty() {
            return Some(OptimizationHint {
                task_id,
                hint_type: HintType::Affinity(AffinityHint {
                    recommended_cpus: underloaded.clone(),
                    preferred: underloaded.first().copied(),
                    avoid_cpus: overloaded,
                    affinity_reason: AffinityReason::LoadBalancing,
                }),
                priority: 30,
                confidence: 70,
                reason: HintReason::LoadBalancing,
                timestamp: Nanoseconds::zero(),
            });
        }
        
        None
    }
    
    fn evaluate_system(&self, _system: &SystemStats) -> Vec<OptimizationHint> {
        Vec::new()
    }
    
    fn update(&mut self, _hint: &OptimizationHint, _success: bool) {}
}

/// Energy optimization strategy
pub struct EnergyStrategy {
    /// Low load threshold for power saving
    low_load_threshold: u8,
    /// High load threshold for performance
    high_load_threshold: u8,
}

impl EnergyStrategy {
    pub fn new() -> Self {
        Self {
            low_load_threshold: 20,
            high_load_threshold: 80,
        }
    }
}

impl OptimizationStrategy for EnergyStrategy {
    fn name(&self) -> &str {
        "energy"
    }
    
    fn evaluate_task(&self, task_id: TaskId, stats: &TaskStats, _system: &SystemStats) -> Option<OptimizationHint> {
        let power_state = if stats.cpu_percent > self.high_load_threshold {
            PowerState::Performance
        } else if stats.cpu_percent < self.low_load_threshold {
            PowerState::PowerSave
        } else {
            return None;
        };
        
        Some(OptimizationHint {
            task_id,
            hint_type: HintType::Energy(EnergyHint {
                power_state,
                allow_scaling: true,
                min_freq: 800,
                max_freq: 4000,
            }),
            priority: 20,
            confidence: 60,
            reason: HintReason::EnergyOptimization,
            timestamp: Nanoseconds::zero(),
        })
    }
    
    fn evaluate_system(&self, system: &SystemStats) -> Vec<OptimizationHint> {
        let mut hints = Vec::new();
        
        // System-wide power management based on load
        if system.cpu_load < self.low_load_threshold && system.runnable_tasks < 5 {
            // Could suggest system-wide power saving
        }
        
        hints
    }
    
    fn update(&mut self, _hint: &OptimizationHint, _success: bool) {}
}

// =============================================================================
// Adaptive Optimizer
// =============================================================================

/// The main adaptive optimizer
pub struct AdaptiveOptimizer {
    /// Prediction engine
    prediction: PredictionEngine,
    /// Active strategies
    strategies: RwLock<Vec<Box<dyn OptimizationStrategy>>>,
    /// Pending hints
    pending_hints: RwLock<VecDeque<OptimizationHint>>,
    /// Applied hints (for tracking)
    applied_hints: RwLock<VecDeque<(OptimizationHint, bool)>>,
    /// Configuration
    config: OptimizerConfig,
    /// Statistics
    stats: OptimizerStats,
    /// Enabled flag
    enabled: AtomicBool,
}

/// Optimizer configuration
#[derive(Debug, Clone)]
pub struct OptimizerConfig {
    /// Maximum pending hints
    pub max_pending_hints: usize,
    /// Maximum applied hints to track
    pub max_applied_hints: usize,
    /// Minimum confidence for applying hint
    pub min_confidence: u8,
    /// Optimization interval
    pub interval: Nanoseconds,
}

impl Default for OptimizerConfig {
    fn default() -> Self {
        Self {
            max_pending_hints: 100,
            max_applied_hints: 1000,
            min_confidence: 50,
            interval: Nanoseconds::from_millis(100),
        }
    }
}

/// Optimizer statistics
#[derive(Debug, Default)]
struct OptimizerStats {
    hints_generated: AtomicU64,
    hints_applied: AtomicU64,
    hints_successful: AtomicU64,
    optimizations_run: AtomicU64,
}

impl AdaptiveOptimizer {
    /// Create new adaptive optimizer
    pub fn new(config: OptimizerConfig) -> Self {
        let mut strategies: Vec<Box<dyn OptimizationStrategy>> = Vec::new();
        strategies.push(Box::new(TimeSliceStrategy::new()));
        strategies.push(Box::new(PriorityStrategy::new()));
        strategies.push(Box::new(LoadBalanceStrategy::new()));
        strategies.push(Box::new(EnergyStrategy::new()));
        
        Self {
            prediction: PredictionEngine::new(PredictionConfig::default()),
            strategies: RwLock::new(strategies),
            pending_hints: RwLock::new(VecDeque::with_capacity(config.max_pending_hints)),
            applied_hints: RwLock::new(VecDeque::with_capacity(config.max_applied_hints)),
            config,
            stats: OptimizerStats::default(),
            enabled: AtomicBool::new(true),
        }
    }
    
    /// Enable or disable optimizer
    pub fn set_enabled(&self, enabled: bool) {
        self.enabled.store(enabled, Ordering::SeqCst);
    }
    
    /// Check if enabled
    pub fn is_enabled(&self) -> bool {
        self.enabled.load(Ordering::SeqCst)
    }
    
    /// Run optimization for a task
    pub fn optimize_task(&self, task_id: TaskId, stats: &TaskStats, system: &SystemStats) {
        if !self.is_enabled() {
            return;
        }
        
        // Update prediction model
        self.prediction.update_task_model(task_id, stats);
        
        // Run all strategies
        let strategies = self.strategies.read();
        for strategy in strategies.iter() {
            if let Some(mut hint) = strategy.evaluate_task(task_id, stats, system) {
                // Only accept high-confidence hints
                if hint.confidence >= self.config.min_confidence {
                    hint.timestamp = system.timestamp;
                    self.add_hint(hint);
                }
            }
        }
        
        self.stats.optimizations_run.fetch_add(1, Ordering::Relaxed);
    }
    
    /// Run system-wide optimization
    pub fn optimize_system(&self, system: &SystemStats) {
        if !self.is_enabled() {
            return;
        }
        
        // Record load for prediction
        self.prediction.record_load(system.timestamp, system.cpu_load, system.runnable_tasks);
        
        // Run system-level strategies
        let strategies = self.strategies.read();
        for strategy in strategies.iter() {
            for hint in strategy.evaluate_system(system) {
                self.add_hint(hint);
            }
        }
    }
    
    /// Add a hint to pending
    fn add_hint(&self, hint: OptimizationHint) {
        let mut pending = self.pending_hints.write();
        if pending.len() >= self.config.max_pending_hints {
            pending.pop_front();
        }
        pending.push_back(hint);
        self.stats.hints_generated.fetch_add(1, Ordering::Relaxed);
    }
    
    /// Get next pending hint
    pub fn pop_hint(&self) -> Option<OptimizationHint> {
        self.pending_hints.write().pop_front()
    }
    
    /// Get all pending hints for a task
    pub fn hints_for_task(&self, task_id: TaskId) -> Vec<OptimizationHint> {
        self.pending_hints.read()
            .iter()
            .filter(|h| h.task_id == task_id)
            .cloned()
            .collect()
    }
    
    /// Record hint outcome
    pub fn record_outcome(&self, hint: OptimizationHint, success: bool) {
        // Update strategy
        let mut strategies = self.strategies.write();
        for strategy in strategies.iter_mut() {
            strategy.update(&hint, success);
        }
        
        // Track applied hints
        let mut applied = self.applied_hints.write();
        if applied.len() >= self.config.max_applied_hints {
            applied.pop_front();
        }
        applied.push_back((hint, success));
        
        self.stats.hints_applied.fetch_add(1, Ordering::Relaxed);
        if success {
            self.stats.hints_successful.fetch_add(1, Ordering::Relaxed);
        }
    }
    
    /// Predict CPU load
    pub fn predict_load(&self) -> LoadPrediction {
        self.prediction.predict_cpu_load(Nanoseconds::from_secs(1))
    }
    
    /// Predict task behavior
    pub fn predict_task(&self, task_id: TaskId) -> TaskPrediction {
        self.prediction.predict_task_behavior(task_id)
    }
    
    /// Get success rate
    pub fn success_rate(&self) -> f64 {
        let applied = self.stats.hints_applied.load(Ordering::Relaxed);
        let successful = self.stats.hints_successful.load(Ordering::Relaxed);
        
        if applied == 0 {
            return 0.0;
        }
        
        (successful as f64 / applied as f64) * 100.0
    }
    
    /// Get optimizer statistics
    pub fn statistics(&self) -> OptimizerStatistics {
        OptimizerStatistics {
            hints_generated: self.stats.hints_generated.load(Ordering::Relaxed),
            hints_applied: self.stats.hints_applied.load(Ordering::Relaxed),
            hints_successful: self.stats.hints_successful.load(Ordering::Relaxed),
            success_rate: self.success_rate(),
            prediction_accuracy: self.prediction.accuracy(),
            optimizations_run: self.stats.optimizations_run.load(Ordering::Relaxed),
        }
    }
    
    /// Register custom strategy
    pub fn register_strategy(&self, strategy: Box<dyn OptimizationStrategy>) {
        self.strategies.write().push(strategy);
    }
}

/// Optimizer statistics snapshot
#[derive(Debug, Clone)]
pub struct OptimizerStatistics {
    pub hints_generated: u64,
    pub hints_applied: u64,
    pub hints_successful: u64,
    pub success_rate: f64,
    pub prediction_accuracy: f64,
    pub optimizations_run: u64,
}

impl Default for AdaptiveOptimizer {
    fn default() -> Self {
        Self::new(OptimizerConfig::default())
    }
}

// =============================================================================
// Learning Module
// =============================================================================

/// Reinforcement learning module for long-term optimization
pub struct LearningModule {
    /// Strategy weights
    strategy_weights: RwLock<BTreeMap<String, f64>>,
    /// Parameter adjustments history
    adjustments: RwLock<Vec<Adjustment>>,
    /// Learning rate
    learning_rate: f64,
    /// Exploration rate (epsilon for epsilon-greedy)
    exploration_rate: f64,
}

/// Record of a parameter adjustment
#[derive(Debug, Clone)]
pub struct Adjustment {
    pub strategy: String,
    pub parameter: String,
    pub old_value: f64,
    pub new_value: f64,
    pub reward: f64,
    pub timestamp: Nanoseconds,
}

impl LearningModule {
    /// Create new learning module
    pub fn new() -> Self {
        Self {
            strategy_weights: RwLock::new(BTreeMap::new()),
            adjustments: RwLock::new(Vec::new()),
            learning_rate: 0.01,
            exploration_rate: 0.1,
        }
    }
    
    /// Initialize weight for a strategy
    pub fn init_strategy(&self, name: &str) {
        self.strategy_weights.write().insert(name.to_string(), 1.0);
    }
    
    /// Get strategy weight
    pub fn get_weight(&self, name: &str) -> f64 {
        *self.strategy_weights.read().get(name).unwrap_or(&1.0)
    }
    
    /// Update strategy weight based on outcome
    pub fn update_weight(&self, name: &str, reward: f64) {
        let mut weights = self.strategy_weights.write();
        let current = *weights.get(name).unwrap_or(&1.0);
        
        // Gradient descent update
        let new_weight = current + self.learning_rate * reward;
        
        // Clamp to reasonable range
        let clamped = new_weight.max(0.1).min(10.0);
        weights.insert(name.to_string(), clamped);
    }
    
    /// Record adjustment
    pub fn record_adjustment(&self, adj: Adjustment) {
        let mut adjustments = self.adjustments.write();
        if adjustments.len() >= 10000 {
            adjustments.remove(0);
        }
        adjustments.push(adj);
    }
    
    /// Should explore (try new things)?
    pub fn should_explore(&self) -> bool {
        // Simple random exploration
        // In real implementation, use proper RNG
        let pseudo_random = core::ptr::addr_of!(self) as u64 % 100;
        (pseudo_random as f64 / 100.0) < self.exploration_rate
    }
    
    /// Get recent adjustments for a strategy
    pub fn recent_adjustments(&self, strategy: &str, limit: usize) -> Vec<Adjustment> {
        self.adjustments.read()
            .iter()
            .rev()
            .filter(|a| a.strategy == strategy)
            .take(limit)
            .cloned()
            .collect()
    }
    
    /// Calculate average reward for strategy
    pub fn average_reward(&self, strategy: &str) -> f64 {
        let adjustments = self.adjustments.read();
        let relevant: Vec<_> = adjustments.iter()
            .filter(|a| a.strategy == strategy)
            .collect();
        
        if relevant.is_empty() {
            return 0.0;
        }
        
        relevant.iter().map(|a| a.reward).sum::<f64>() / relevant.len() as f64
    }
}

impl Default for LearningModule {
    fn default() -> Self {
        Self::new()
    }
}

// =============================================================================
// Tests
// =============================================================================

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_time_slice_strategy() {
        let strategy = TimeSliceStrategy::new();
        
        let mut stats = TaskStats::new();
        stats.behavior_pattern = BehaviorPattern::CpuBound;
        stats.interactive_score = 20;
        
        let system = SystemStats::default();
        
        let hint = strategy.evaluate_task(TaskId::new(1), &stats, &system);
        assert!(hint.is_some());
        
        if let Some(h) = hint {
            if let HintType::TimeSlice(ts) = h.hint_type {
                assert_eq!(ts.recommended.as_millis(), 50);
            } else {
                panic!("Wrong hint type");
            }
        }
    }
    
    #[test]
    fn test_prediction_engine() {
        let engine = PredictionEngine::new(PredictionConfig::default());
        
        // Add some samples
        for i in 0..20 {
            engine.record_load(
                Nanoseconds::from_secs(i as u64),
                50 + (i % 10) as u8,
                10
            );
        }
        
        let prediction = engine.predict_cpu_load(Nanoseconds::from_secs(1));
        assert!(prediction.predicted_load > 0);
    }
    
    #[test]
    fn test_adaptive_optimizer() {
        let optimizer = AdaptiveOptimizer::default();
        
        let stats = TaskStats::new();
        let system = SystemStats::default();
        
        optimizer.optimize_task(TaskId::new(1), &stats, &system);
        
        // Stats should be updated
        let opt_stats = optimizer.statistics();
        assert!(opt_stats.optimizations_run >= 1);
    }
}
